{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA3vEBn4Fbpt",
        "outputId": "b37ae10d-11a5-4dee-df56-c1c532a0383e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "3/3 [==============================] - 10s 835ms/step - loss: 15851.8496 - val_loss: 19655.4180\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 15850.5146 - val_loss: 19653.5391\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 15849.1074 - val_loss: 19651.5703\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 15847.5000 - val_loss: 19649.3633\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 15845.7842 - val_loss: 19646.8047\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 15843.8965 - val_loss: 19643.8477\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 15841.6533 - val_loss: 19640.4863\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 15839.1299 - val_loss: 19636.6016\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 15836.2500 - val_loss: 19632.0801\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 15832.9980 - val_loss: 19626.7051\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 15829.0156 - val_loss: 19620.2891\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 15824.5410 - val_loss: 19612.4570\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 15819.0215 - val_loss: 19603.0703\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 15812.0752 - val_loss: 19591.8477\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 15804.3604 - val_loss: 19578.4551\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 15795.6572 - val_loss: 19562.0820\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 15784.4141 - val_loss: 19542.0957\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 15769.7285 - val_loss: 19517.7969\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 15754.6289 - val_loss: 19488.0391\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 15734.7246 - val_loss: 19453.2598\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 15711.7607 - val_loss: 19411.6875\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 15684.8555 - val_loss: 19360.3516\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 15652.0674 - val_loss: 19298.5781\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 15611.6250 - val_loss: 19226.4316\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 15564.2373 - val_loss: 19143.9668\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 15509.1680 - val_loss: 19049.4629\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 15445.2979 - val_loss: 18946.2695\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 15368.4639 - val_loss: 18839.1602\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 15292.8105 - val_loss: 18725.0059\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 15206.3486 - val_loss: 18607.1465\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 15118.6943 - val_loss: 18489.2227\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 15030.1123 - val_loss: 18377.3418\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 14942.7578 - val_loss: 18273.8594\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 14860.5264 - val_loss: 18177.2188\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 14783.1406 - val_loss: 18089.5137\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 14703.5684 - val_loss: 18009.3633\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 14632.4492 - val_loss: 17934.1777\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 14570.2451 - val_loss: 17861.3867\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 14508.6533 - val_loss: 17795.0586\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 14453.1807 - val_loss: 17734.6211\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 14401.4238 - val_loss: 17680.6016\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 14351.6475 - val_loss: 17630.6738\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 14310.2832 - val_loss: 17584.0410\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 14270.8359 - val_loss: 17540.8691\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 14237.5166 - val_loss: 17499.0371\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 14201.8330 - val_loss: 17461.1777\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 14169.5498 - val_loss: 17425.4590\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 14139.8818 - val_loss: 17389.8711\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 14112.8867 - val_loss: 17356.2090\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 14084.7627 - val_loss: 17324.8398\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 10484.9844\n",
            "Test Loss: 10484.984375\n",
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('train_delay.csv')\n",
        "\n",
        "# Assuming 'delay' is the column representing train delays\n",
        "# You may need to preprocess your data to extract features and preprocess them accordingly\n",
        "# Here we're assuming 'X' contains features and 'y' contains the target delays\n",
        "X = data.drop(columns=['delay', 'id']).values.reshape(-1, 1)  # Assuming 'id' is not a feature and reshaping to 2D\n",
        "y = data['delay'].values\n",
        "\n",
        "# Normalize the features\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape the input data to fit LSTM input shape (samples, time steps, features)\n",
        "# Assuming you want to use 10 timesteps (you can adjust this based on your dataset)\n",
        "timesteps = min(10, len(X_train))  # Adjust to the minimum of 10 or the length of your training data\n",
        "n_features = 1  # Assuming univariate time series (only the 'delay' column)\n",
        "X_train_reshaped = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))  # Reshaping to (samples, 1, features)\n",
        "X_test_reshaped = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))  # Reshaping to (samples, 1, features)\n",
        "\n",
        "\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
        "model.add(LSTM(units=50, return_sequences=True))\n",
        "model.add(LSTM(units=50))\n",
        "model.add(Dense(units=1))  # Output layer\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Define early stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "\n",
        "# Predict train delays\n",
        "predictions = model.predict(X_test_reshaped)\n",
        "\n",
        "# You can further evaluate your predictions using metrics like MAE, RMSE, etc.\n"
      ]
    }
  ]
}